{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 3.1: Custome_NER_Spacy3.x.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOqIdEFRMXCVT2fgtr1Az0u",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gulabpatel/NER/blob/main/Part%203.1%3A%20Custome_NER_Spacy3.x.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-1LNdGPHVIH"
      },
      "source": [
        "#NER, Spacy 3.x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riAhBNrqH1GI"
      },
      "source": [
        "pip install -U spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EhZSTAHmR1yk",
        "outputId": "9b95e04a-b44a-46a7-eece-0a944c1ef0e9"
      },
      "source": [
        "import spacy\n",
        "spacy.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.1.4'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJO2R9LlHYI3"
      },
      "source": [
        "#Import all required libraries\n",
        "import spacy\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import sys\n",
        "from spacy import displacy\n",
        "from itertools import chain\n",
        "import matplotlib.pyplot as plt \n",
        "from matplotlib.ticker import MaxNLocator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFE-Zd_FIRd_"
      },
      "source": [
        "The below method is used to convert the train and validation data from old format to new format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-apgh9QTj4I"
      },
      "source": [
        "train_data = [         \n",
        "(\"Changeover to PO use case \",{\"entities\":[(0,10,\"switch\"),(17,25,\"usecase\")]}),\n",
        "(\"Changeover to PMR use case \",{\"entities\":[(0,10,\"switch\"),(18,26,\"usecase\")]}),\n",
        "(\"Go to PO use case \",{\"entities\":[(0,5,\"switch\"),(9,17,\"usecase\")]}),\n",
        "(\"Go to PMR use case \",{\"entities\":[(0,5,\"switch\"),(10,18,\"usecase\")]}),\n",
        "(\"Switch to the PO use case \",{\"entities\":[(0,6,\"switch\"),(17,25,\"usecase\")]}),\n",
        "(\"Switch to PMR use case \",{\"entities\":[(0,6,\"switch\"),(14,22,\"usecase\")]}),\n",
        "(\"Show me last 20 questions \",{\"entities\":[(0,4,\"display\"),(16,25,\"question\")]}),\n",
        "(\"Show me last 20 questions \",{\"entities\":[(0,4,\"display\"),(16,25,\"question\")]}),\n",
        "(\"Display me all the questions I queried about last day \",{\"entities\":[(0,7,\"display\"),(19,28,\"question\")]}),\n",
        "(\"Show me all the questions I queried about last day \",{\"entities\":[(0,4,\"display\"),(16,25,\"question\")]}),\n",
        "(\"Changeover to PO usecase \",{\"entities\":[(0,10,\"switch\"),(17,24,\"usecase\")]}),\n",
        "(\"Changeover to PMR usecase \",{\"entities\":[(0,10,\"switch\"),(18,25,\"usecase\")]}),\n",
        "(\"Go to PO usecase \",{\"entities\":[(0,5,\"switch\"),(9,16,\"usecase\")]}),\n",
        "(\"Go to PMR usecase \",{\"entities\":[(0,5,\"switch\"),(10,17,\"usecase\")]}),\n",
        "(\"Switch to the PO usecase \",{\"entities\":[(0,6,\"switch\"),(17,24,\"usecase\")]}),\n",
        "(\"Switch to PMR usecase \",{\"entities\":[(0,6,\"switch\"),(14,21,\"usecase\")]}),\n",
        "(\"Go to next use case \",{\"entities\":[(0,5,\"switch\"),(11,19,\"usecase\")]}),\n",
        "(\"Go to previous use case \",{\"entities\":[(0,5,\"switch\"),(15,23,\"usecase\")]}),\n",
        "(\"Switch to the next use case \",{\"entities\":[(0,6,\"switch\"),(19,27,\"usecase\")]}),\n",
        "(\"Switch to the Previous use case \",{\"entities\":[(0,6,\"switch\"),(23,31,\"usecase\")]}),\n",
        "(\"Go to next usecase \",{\"entities\":[(0,5,\"switch\"),(11,18,\"usecase\")]}),\n",
        "(\"Go to previous usecase \",{\"entities\":[(0,5,\"switch\"),(15,22,\"usecase\")]}),\n",
        "(\"Switch to the next usecase \",{\"entities\":[(0,6,\"switch\"),(19,26,\"usecase\")]}),\n",
        "(\"Switch to the Previous usecase \",{\"entities\":[(0,6,\"switch\"),(23,30,\"usecase\")]}),\n",
        "(\"General settings \",{\"entities\":[(8,16,\"settings\")]}),\n",
        "(\"Email Strategy synchrony \",{\"entities\":[(0,5,\"email\"),(6,14,\"strategy\")]}),\n",
        "(\"Mute ASK \",{\"entities\":[(0,4,\"mute\")]}),\n",
        "(\"Can you please Mute the ASK module \",{\"entities\":[(15,19,\"mute\")]}),\n",
        "(\"Display settings \",{\"entities\":[(0,7,\"display\"),(8,16,\"settings\")]}),\n",
        "(\"Open General settings \",{\"entities\":[(0,4,\"display\"),(13,21,\"settings\")]}),\n",
        "(\"Volume Up \",{\"entities\":[(0,6,\"volume\"),(7,9,\"increase\")]}),\n",
        "(\"stop it \",{\"entities\":[(0,4,\"stop\")]}),\n",
        "(\"hold it \",{\"entities\":[(0,4,\"stop\")]}),\n",
        "(\"Suspend it \",{\"entities\":[(0,7,\"stop\")]}),\n",
        "(\"Freeze it \",{\"entities\":[(0,6,\"stop\")]}),\n",
        "(\"Enable the Silent mode for ASK module \",{\"entities\":[(11,17,\"mute\")]}),\n",
        "(\"Put the Silent Mode ON for ASK module \",{\"entities\":[(8,14,\"mute\")]}),\n",
        "(\"Can you please put the ASK module on silent mode \",{\"entities\":[(37,43,\"mute\")]}),\n",
        "(\"Can you please Silent the ASK module \",{\"entities\":[(15,21,\"mute\")]}),\n",
        "(\"Enable mute for ASK \",{\"entities\":[(7,11,\"mute\")]}),\n",
        "(\"make a new adaptation schema \",{\"entities\":[(0,4,\"create\"),(11,28,\"adaptation schema\")]}),\n",
        "(\"Decrease Volume \",{\"entities\":[(9,15,\"volume\"),(0,8,\"decrease\")]}),\n",
        "(\"Increase volume \",{\"entities\":[(0,8,\"increase\"),(9,15,\"volume\")]}),\n",
        "(\"Volume Down \",{\"entities\":[(0,6,\"volume\"),(7,11,\"decrease\")]}),\n",
        "(\"Open the case a \",{\"entities\":[(0,4,\"display\"),(9,13,\"case\")]}),\n",
        "(\"show clip case 123 \",{\"entities\":[(0,4,\"display\"),(10,14,\"case\")]}),\n",
        "(\"create latest adaptation schema \",{\"entities\":[(0,6,\"create\"),(14,31,\"adaptation schema\")]}),\n",
        "(\"create a new adaptation schema \",{\"entities\":[(0,6,\"create\"),(13,30,\"adaptation schema\")]}),\n",
        "(\"build a new adaptation schema \",{\"entities\":[(0,5,\"create\"),(12,29,\"adaptation schema\")]}),\n",
        "(\"define a new adaptation schema \",{\"entities\":[(0,6,\"create\"),(13,30,\"adaptation schema\")]}),\n",
        "(\"Open first case z \",{\"entities\":[(0,4,\"display\"),(11,15,\"case\")]}),\n",
        "(\"Show last case x \",{\"entities\":[(0,4,\"display\"),(10,14,\"case\")]}),\n",
        "(\"render me my adaptation schemas \",{\"entities\":[(0,6,\"display\"),(13,31,\"adaptation schemas\")]}),\n",
        "(\"Pull adaptation schemas \",{\"entities\":[(0,4,\"display\"),(5,23,\"adaptation schemas\")]}),\n",
        "(\"my adaptation schemas \",{\"entities\":[(3,21,\"adaptation schemas\")]}),\n",
        "(\"Display my adaptation schemas \",{\"entities\":[(0,7,\"display\"),(11,29,\"adaptation schemas\")]}),\n",
        "(\"open my adaptation schemas \",{\"entities\":[(0,4,\"display\"),(8,26,\"adaptation schemas\")]}),\n",
        "(\"show me my adaptation schemas \",{\"entities\":[(0,4,\"display\"),(11,29,\"adaptation schemas\")]}),\n",
        "(\"display the schema named XYZ \",{\"entities\":[(0,7,\"display\"),(12,18,\"adaptation schemas\")]}),\n",
        "(\"show the schema named pqr \",{\"entities\":[(0,4,\"display\"),(9,15,\"adaptation schemas\")]}),\n",
        "(\"Open the schema named XYZ \",{\"entities\":[(0,4,\"display\"),(9,15,\"adaptation schemas\")]}),\n",
        "(\"display schema XYZ \",{\"entities\":[(0,7,\"display\"),(8,14,\"adaptation schemas\")]}),\n",
        "(\"Build decision flow using schema XYZ \",{\"entities\":[(0,5,\"create\"),(6,19,\"decision flow\")]}),\n",
        "(\"produce decision flow using schema XYZ \",{\"entities\":[(0,7,\"create\"),(8,21,\"decision flow\")]}),\n",
        "(\"make decision flow using schema abc \",{\"entities\":[(0,4,\"create\"),(5,18,\"decision flow\")]}),\n",
        "(\"create decision flow using schema XYZ \",{\"entities\":[(0,6,\"create\"),(7,20,\"decision flow\")]}),\n",
        "(\"give decision flow klm \",{\"entities\":[(0,4,\"display\"),(5,18,\"decision flow\")]}),\n",
        "(\"Show decision flow XYZ \",{\"entities\":[(0,4,\"display\"),(5,18,\"decision flow\")]}),\n",
        "(\"clip decision flow mno \",{\"entities\":[(0,4,\"display\"),(5,18,\"decision flow\")]}),\n",
        "(\"Display decision flow abc \",{\"entities\":[(0,7,\"display\"),(8,21,\"decision flow\")]}),\n",
        "(\"Render decision flow pqr \",{\"entities\":[(0,6,\"display\"),(7,20,\"decision flow\")]}),\n",
        "(\"SHow me opportunities with highest impact \",{\"entities\":[(0,4,\"display\"),(8,21,\"opportunities\")]}),\n",
        "(\"opportunities available for me \",{\"entities\":[(0,13,\"opportunities\")]}),\n",
        "(\"What are the available opportunities for me \",{\"entities\":[(0,4,\"display\"),(23,36,\"opportunities\")]}),\n",
        "(\"Display the available opportunities for me \",{\"entities\":[(0,7,\"display\"),(22,35,\"opportunities\")]}),\n",
        "(\"Show me available opportunities for me \",{\"entities\":[(0,4,\"display\"),(18,31,\"opportunities\")]}),\n",
        "(\"my strategies \",{\"entities\":[(3,13,\"strategies\")]}),\n",
        "(\"What are the strategies shared with me \",{\"entities\":[(0,4,\"display\"),(13,23,\"strategies\")]}),\n",
        "(\"strategies shared with me \",{\"entities\":[(0,10,\"strategies\"),(11,17,\"display\")]}),\n",
        "(\"Show me strategies shared with me \",{\"entities\":[(0,4,\"display\"),(8,18,\"strategies\")]}),\n",
        "(\"What are my strategies \",{\"entities\":[(0,4,\"display\"),(12,22,\"strategies\")]}),\n",
        "(\"Display my strategies \",{\"entities\":[(0,7,\"display\"),(11,21,\"strategies\")]}),\n",
        "(\"Show me my strategies \",{\"entities\":[(0,4,\"display\"),(11,21,\"strategies\")]}),\n",
        "(\"What are the Opportunities with highest impact \",{\"entities\":[(0,4,\"display\"),(13,26,\"opportunities\")]}),\n",
        "(\"Display opportunities with highest impact \",{\"entities\":[(0,7,\"display\"),(8,21,\"opportunities\")]}),\n",
        "              ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ4g-ZzkISW-",
        "outputId": "cf7c7eb4-3eae-41f7-aa93-0d1915cdad6a"
      },
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "nlp = spacy.blank(\"en\") # load a new spacy model\n",
        "db = DocBin() # create a DocBin object\n",
        "\n",
        "for text, annot in tqdm(train_data): # data in previous format\n",
        "    doc = nlp.make_doc(text) # create doc object from text\n",
        "    ents = []\n",
        "    for start, end, label in annot[\"entities\"]: # add character indexes\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    doc.ents = ents # label the text with the ents\n",
        "    db.add(doc)\n",
        "\n",
        "db.to_disk(\"./train.spacy\") # save the docbin object\n",
        "\n",
        "db = DocBin()\n",
        "for text, annot in tqdm(train_data): # data in previous format\n",
        "    doc = nlp.make_doc(text) # create doc object from text\n",
        "    ents = []\n",
        "    for start, end, label in annot[\"entities\"]: # add character indexes\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    doc.ents = ents # label the text with the ents\n",
        "    db.add(doc)\n",
        "\n",
        "db.to_disk(\"./valid.spacy\") # save the docbin object\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 191/191 [00:00<00:00, 1657.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 191/191 [00:00<00:00, 1990.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHn6UFqwJazo"
      },
      "source": [
        "Create base config file from here: https://spacy.io/usage/training#quickstart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXX0JJBsv_XK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc91154c-0518-4f0c-bb72-6f2587b9729a"
      },
      "source": [
        "#!python -m spacy init fill-config base_config.cfg config.cfg  ##comment it after running once"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f16S7oHRJhpk"
      },
      "source": [
        "Train using CLI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgaO3MBp7nyp"
      },
      "source": [
        "!python -m spacy download en_core_web_lg\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkLWvibPJjn_",
        "outputId": "f88758ac-95d5-493f-e90b-092ea0970c73"
      },
      "source": [
        "!python -m spacy train /content/config.cfg --verbose --output ./ner_demo/training/ --paths.train /content/train.spacy --paths.dev /content/train.spacy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2021-11-02 11:05:27,679] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev']\n",
            "\u001b[38;5;2m✔ Created output directory: ner_demo/training\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: ner_demo/training\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2021-11-02 11:05:28,052] [INFO] Set up nlp object from config\n",
            "[2021-11-02 11:05:28,066] [DEBUG] Loading corpus from path: /content/train.spacy\n",
            "[2021-11-02 11:05:28,068] [DEBUG] Loading corpus from path: /content/train.spacy\n",
            "[2021-11-02 11:05:28,068] [INFO] Pipeline: ['tok2vec', 'ner']\n",
            "[2021-11-02 11:05:28,075] [INFO] Created vocabulary\n",
            "[2021-11-02 11:05:31,586] [INFO] Added vectors: en_core_web_lg\n",
            "tcmalloc: large alloc 1643593728 bytes == 0x557453ae4000 @  0x7f1ba2b5a2a4 0x7f1b910f88bd 0x7f1b910f7a9d 0x7f1b910f4275 0x7f1b910f4a1e 0x557410e112ed 0x557410f02e1d 0x557410e84e99 0x557410e7f9ee 0x557410e12bda 0x557410e81737 0x7f1a4c097918 0x7f1a4c0991fe 0x7f1a4c09e947 0x7f1a4c09fd42 0x557410e11c52 0x557410e84c25 0x557410e12afa 0x557410e80915 0x7f1a4c097918 0x7f1a4c0991fe 0x7f1a4c09e470 0x557410e114b0 0x557410f02e1d 0x557410e84e99 0x557410e7fced 0x557410e12bda 0x557410e81737 0x557410e7fced 0x557410e12bda 0x557410e81737\n",
            "tcmalloc: large alloc 1662509056 bytes == 0x5574e7c1c000 @  0x7f1ba2b5a2a4 0x7f1b910f5fd3 0x7f1b910f7a9d 0x7f1b910f4275 0x7f1b910f4a1e 0x557410e112ed 0x557410f02e1d 0x557410e84e99 0x557410e7f9ee 0x557410e12bda 0x557410e81737 0x557410e12afa 0x557410e84d00 0x7f1a4c097918 0x7f1a4c0991fe 0x7f1a4c09e470 0x557410e114b0 0x557410f02e1d 0x557410e84e99 0x557410e7fced 0x557410e12bda 0x557410e81737 0x557410e7fced 0x557410e12bda 0x557410e81737 0x557410e7fced 0x557410e12bda 0x557410e81737 0x557410e7fced 0x557410e12bda 0x557410e81737\n",
            "[2021-11-02 11:05:37,368] [INFO] Finished initializing nlp object\n",
            "[2021-11-02 11:05:37,848] [DEBUG] [W033] Training a new parser or NER using a model with no lexeme normalization table. This may degrade the performance of the model to some degree. If this is intentional or the language you're using doesn't have a normalization table, please ignore this warning. If this is surprising, make sure you have the spacy-lookups-data package installed and load the table in your config. The languages with lexeme normalization tables are currently: cs, da, de, el, en, id, lb, mk, pt, ru, sr, ta, th\n",
            "\n",
            "Load the table in your config with:\n",
            "\n",
            "[initialize.lookups]\n",
            "@misc = \"spacy.LookupsDataLoader.v1\"\n",
            "lang = ${nlp.lang}\n",
            "tables = [\"lexeme_norm\"]\n",
            "\n",
            "[2021-11-02 11:05:38,124] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "[2021-11-02 11:05:38,144] [DEBUG] Loading corpus from path: /content/train.spacy\n",
            "[2021-11-02 11:05:38,147] [DEBUG] Loading corpus from path: /content/train.spacy\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     69.59   12.40    8.43   23.40    0.12\n",
            " 20     200         15.93   1961.35   99.72   99.72   99.72    1.00\n",
            " 46     400          8.01     68.83   99.72   99.72   99.72    1.00\n",
            " 77     600          6.61     69.78   99.72   99.72   99.72    1.00\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "ner_demo/training/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQe7sVrG_c0W"
      },
      "source": [
        "TEST_DATA = [\n",
        "\"Send previous use case\",\n",
        "\"Go to Ask module\t\",\n",
        "\"display PMR usecase\t\",\n",
        "\"display adaptation schema\",\t\n",
        "\"increase the questions I asked yesterday\",\n",
        "\"adjust usecase\",\t\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiFx8Qb9JpwU"
      },
      "source": [
        "ner = spacy.load(R\"ner_demo/training/model-best\") #load the best model\n",
        "\n",
        "test_sentences = [x for x in TEST_DATA] # extract the sentences from [sentence, entity]\n",
        "for x in test_sentences:\n",
        "    doc = ner(x)\n",
        "    for ent in doc.ents:\n",
        "        print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
        "    displacy.render(doc,jupyter=True, style = \"ent\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9GTLC2gGlgk"
      },
      "source": [
        "test_data = [\n",
        "'musturn up adaptation schema',\n",
        "'musturn up new user',\n",
        "'remit this inquiry',\n",
        "'remit this ques',\n",
        "'remit this query',\n",
        "'layout me all the query I asked last day'\n",
        "]\n",
        "ner = spacy.load(R\"ner_demo/training/model-best\") #load the best model\n",
        "\n",
        "test_sentences = [x for x in test_data] # extract the sentences from [sentence, entity]\n",
        "for x in test_sentences:\n",
        "    start = time.time()\n",
        "    doc = ner(x)\n",
        "    for ent in doc.ents:\n",
        "        print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
        "    end = time.time()\n",
        "    print(f\"Runtime of the above query is {end - start}\")\n",
        "    displacy.render(doc,jupyter=True, style = \"ent\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl4a6katG20s"
      },
      "source": [
        "-----------------------"
      ]
    }
  ]
}